# MultiModalDataFusion-Module

## Exercise topics:

1. Introduction and Sensors and architectures
2. Common representation
3. Data alignment
4. Bayesian inference and parameter estimation
5. Sequential Bayesian inference
6. Bayesian decision theory and ensemble learning

## Project:

The goal of this project is to develop user-independent pre-processing and classification models to recognize 7 different physical exercises measured by accelerometer (attached to subject's thigh) and depth camera (above the subject facing downwards recording an aerial view). All the exercises were performed subject lying down on the mat. Original dataset have also another acceleration sensor and pressure-sensitive mat, but those two modalities are ommited in this project. There are totally 30 subjects in the original dataset, and in this work subset of 10 person is utilized. Detailed description of the dataset and original data can be access in MEx dataset @ UCI machine learning repository.

The project work is divided on following phases:

1. Data preparation, exploration, and visualization
2. Feature extraction and unimodal fusion for classification
3. Feature extraction and feature-level fusion for multimodal classification
4. Decision-level fusion for multimodal classification
5. Bonus task: Multimodal biometric identification of persons (Not done)


[Course description link](https://opas.peppi.oulu.fi/en/course/521161S/7561)
